<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://eugenebang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://eugenebang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-03T06:08:11+00:00</updated><id>https://eugenebang.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ğŸ’ŠğŸ¤– Insilicoâ€™s Rentosertib: A Turning Point for AI in Drug Discovery</title><link href="https://eugenebang.github.io/blog/2025/Rentosertib/" rel="alternate" type="text/html" title="ğŸ’ŠğŸ¤– Insilicoâ€™s Rentosertib: A Turning Point for AI in Drug Discovery"/><published>2025-07-02T16:40:16+00:00</published><updated>2025-07-02T16:40:16+00:00</updated><id>https://eugenebang.github.io/blog/2025/Rentosertib</id><content type="html" xml:base="https://eugenebang.github.io/blog/2025/Rentosertib/"><![CDATA[<p>A quiet but profound milestone just unfolded in AI-enabled drug discovery: Rentosertib, an AI-discovered drug by <a href="https://insilico.com/">Insilico Medicine</a>, has passed a phase 2a clinical trial for idiopathic pulmonary fibrosis (IPF).</p> <p>Few AI-designed candidates have moved beyond <em>in silico</em> hype. <a href="https://www.nature.com/articles/s41591-025-03743-2">This study, reported in <em>Nature Medicine</em></a>, marks a real-world success, demonstrating that AI can do more than generate molecules fasterâ€”it can guide discovery, de-risk development, and reshape how we develop medicines. ğŸ§¬ğŸ’Š</p> <hr/> <h3 id="-why-did-this-ai-generated-drug-advance">ğŸ” Why did <em>THIS</em> AI-generated drug advance?</h3> <p>This monumental accomplishment has also been reviewed by <a href="https://dbmi.hms.harvard.edu/people/marinka-zitnik">Prof. Markina Zitnik</a> of HMS on <a href="https://www.nature.com/articles/s41591-025-03832-2">her commentary</a>, also on <em>Nature Medicine</em>. While many AI-designed molecules remain stuck at benchmark papers and conference slides, rentosertib advanced because of an integrated, upstream innovation pipeline:</p> <h4 id="-cross-disease-target-discovery--time-machine-modeling">ğŸ¯ Cross-disease target discovery &amp; â€˜time-machineâ€™ modeling:</h4> <p>AI models trained on historical data predicted TNIK as a promising target for fibrosis years before traditional pipelines, showcasing AIâ€™s ability to see around corners.</p> <h4 id="-robust-biological-validation">ğŸ”¬ Robust biological validation:</h4> <p>Multi-omic analyses, network biology, and deep literature mining validated TNIKâ€™s relevance in fibrosis, aligning computational predictions with biological reality.</p> <h4 id="ï¸-ai-driven-chemistry-design">âš™ï¸ AI-driven chemistry design:</h4> <p>Generative models designed molecules for novel binding sites while prioritizing drug-likeness, synthetic feasibility, pharmacokinetics, and potency early in the pipeline.</p> <hr/> <h2 id="-what-this-means-for-ai-x-medicine">ğŸŒ± What this means for AI x Medicine</h2> <p>This milestone reminds us: AIâ€™s promise in drug discovery isnâ€™t just about speed or cost reduction, but in enabling new science. By combining cross-modal data integration, generative modeling, and rigorous biological validation, AI can unlock targets, design candidates, and advance therapies that traditional pipelines might miss.</p> <p>For those of us working at the intersection of AI x medicine, this is an exciting signal that the promise of AI-enabled drug discovery is moving from papers to patients.</p> <h4 id="-looking-ahead">âœ¨ Looking ahead</h4> <p>Insilico Medicineâ€™s excitement and the communityâ€™s momentum reflect a broader shift: integrating AI deeply across target discovery, validation, and design pipelines is becoming essential.</p> <p>As we move forward, milestones like these give us reason to believe that AI can meaningfully contribute to addressing unmet medical needs, not someday, but now.</p> <p><em>ğŸ“Œ For those interested in digging deeper, I recommend reading Marinka Zitnikâ€™s commentary in Nature Medicine, along with the two papers (<a href="https://www.nature.com/articles/s41587-024-02143-0">Nature Biotech, 20244</a> and <a href="https://www.nature.com/articles/s41591-025-03743-2">Nature Medicine, 2025</a>) documenting rentosertibâ€™s discovery and development.</em></p>]]></content><author><name></name></author><category term="News"/><category term="AIDD"/><summary type="html"><![CDATA[Insilico Medicine's Rentosertib passes a phase 2a clinical trial for idiopathic pulmonary fibrosis (IPF).]]></summary></entry><entry><title type="html">ğŸš€ Arcâ€™s Virtual Cell Challenge: Accelerating Drug Discovery with AI Models</title><link href="https://eugenebang.github.io/blog/2025/virtual-cell-ark-institue/" rel="alternate" type="text/html" title="ğŸš€ Arcâ€™s Virtual Cell Challenge: Accelerating Drug Discovery with AI Models"/><published>2025-06-29T16:40:16+00:00</published><updated>2025-06-29T16:40:16+00:00</updated><id>https://eugenebang.github.io/blog/2025/virtual-cell-ark-institue</id><content type="html" xml:base="https://eugenebang.github.io/blog/2025/virtual-cell-ark-institue/"><![CDATA[<p>ğŸ§¬ What if we could predict how cells change state under different conditions, and discover drugs to shift â€œdiseasedâ€ cells back to â€œhealthyâ€ ones? The Arc Institute is taking a major step toward this vision with the launch of the inaugural Virtual Cell Challenge, a public competition offering $100,000+ in prizes for the best machine learning models predicting cellular responses to genetic perturbations.</p> <h4 id="-why-is-this-hard">ğŸ§ª Why is this hard?</h4> <p>â€œCells are living dynamic systems,â€ explains Yusuf Roohani, PhD, ML group lead at Arc. â€œTheyâ€™re constantly in flux, messy, and experiment-dependent.â€ Virtual cell models must account for cell type, genetic background, and context while navigating technical noise and inconsistent reproducibility across datasetsâ€”challenges that have slowed progress and made benchmarking difficult.</p> <h4 id="-a-new-benchmark-for-the-community">ğŸ† A new benchmark for the community</h4> <p>Modeled after CASP (which transformed protein structure prediction and paved the way for AlphaFold), Arcâ€™s challengeâ€”described in a new Cell commentary led by Roohaniâ€”aims to align the community around standardized evaluation for virtual cells. Sponsored by Nvidia, 10x Genomics, and Ultima Genomics, the competition invites academia, biotech, and independent researchers to participate.</p> <p>ğŸ”¬ For the competition, Arc generated a new single-cell transcriptomics dataset of 300,000 human embryonic stem cells with 300 genetic perturbations, rolled out in phases for fine-tuning, validation, and testing. Models will be evaluated on:</p> <p>1ï¸âƒ£ Predicting differentially expressed genes<br/> 2ï¸âƒ£ Discriminating perturbation effects<br/> 3ï¸âƒ£ General error in expression count deviation</p> <h3 id="state-virtual-cell-model-from-arc-institute">STATE: virtual cell model from Arc Institute</h3> <p>Competitors will initially face off against Arcâ€™s own STATE model, released last week for non-commercial use. Composed of:</p> <p>ğŸ”¹ <strong>State Transition (ST) module:</strong> Uses data from 100M+ perturbed cells across 70 contexts, leveraging a bi-directional transformer to predict perturbation effects across cell collections.<br/> ğŸ”¹ <strong>State Embedding (SE) module:</strong> Trained on 167M human cells to learn robust gene expression variation, optimized for detecting biological perturbations while handling technical noise.</p> <p>The STATE model has shown over 50% improvement in perturbation effect discrimination and 2x accuracy in identifying differentially expressed genes compared to existing models.</p> <h4 id="-why-this-matters">ğŸ©º Why this matters:</h4> <p>If successful, virtual cell models could transform drug discovery and precision medicine, enabling the design of interventions with fewer off-target effects and higher clinical success rates.</p> <p>For those interested, registration is open now, with final evaluations happening in late October and winners revealed in December. This could be the next frontier in biology x AIâ€”and your team could help build it. ğŸŒ±</p>]]></content><author><name></name></author><category term="SOTA"/><category term="Competition"/><category term="virtualcell"/><summary type="html"><![CDATA[The Arc Institute is taking a major step toward this vision with the launch of the inaugural Virtual Cell Challenge, a public competition offering $100,000+ in prizes for the best machine learning models predicting cellular responses to genetic perturbations.]]></summary></entry><entry><title type="html">ğŸ§¬ DeepMind releases AlphaGenome, a New AI Model for Decoding the Genome</title><link href="https://eugenebang.github.io/blog/2025/alphagenome/" rel="alternate" type="text/html" title="ğŸ§¬ DeepMind releases AlphaGenome, a New AI Model for Decoding the Genome"/><published>2025-06-25T16:40:16+00:00</published><updated>2025-06-25T16:40:16+00:00</updated><id>https://eugenebang.github.io/blog/2025/alphagenome</id><content type="html" xml:base="https://eugenebang.github.io/blog/2025/alphagenome/"><![CDATA[<p>DeepMind has unveiled <a href="https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/">AlphaGenome</a>, a <strong>unifying DNA sequence model</strong> that advances regulatory variant-effect prediction and promises to illuminate the function of the human genomeâ€”now available via API for non-commercial research.</p> <hr/> <h4 id="-why-it-matters">ğŸ” Why it matters</h4> <p>The genome is our cellular instruction manual, but deciphering how its instructions are readâ€”and how small DNA variations affect biologyâ€”remains one of scienceâ€™s deepest challenges. Variants in non-coding regions, which make up 98% of the genome, play critical roles in orchestrating gene activity and disease susceptibility.</p> <p>AlphaGenome aims to address this, predicting how single variants or mutations impact a wide range of biological processes regulating genes with higher resolution than before.</p> <h4 id="ï¸-how-alphagenome-works">âš™ï¸ How AlphaGenome works</h4> <p>AlphaGenome can process long DNA sequences (up to 1 million base-pairs) and predict thousands of molecular properties, including:</p> <p>ğŸ”¹ Gene start and end sites across tissues<br/> ğŸ”¹ RNA production levels<br/> ğŸ”¹ DNA accessibility, proximity, and protein binding sites</p> <p>It evaluates the effects of mutations by comparing predictions for mutated and unmutated sequences, providing a direct readout of potential functional consequences.</p> <p>The architecture combines convolutional layers (to detect local patterns), transformers (to model long-range dependencies), and final modality-specific layers, distributing training across interconnected TPUs for efficiency.</p> <p>AlphaGenome builds on DeepMindâ€™s previous model, Enformer, and complements AlphaMissense, extending variant-effect prediction from protein-coding regions (2% of the genome) to the vast non-coding regions that shape gene regulation.</p> <h4 id="-why-this-is-exciting">ğŸŒ± Why this is exciting</h4> <p>It seems like integration of 3D and multi-scale genomic information is becoming essential for decoding gene regulation and variant effects. AlphaGenome is a step toward that vision, offering:</p> <p>âœ… A scalable, open-access tool for the research community<br/> âœ… Potential insights into disease mechanisms<br/> âœ… Foundations for new therapeutic discoveries</p> <p>By making AlphaGenome available via API, DeepMind is inviting the community to explore and validate this model, accelerating our collective progress in interpreting the genomeâ€™s language.</p>]]></content><author><name></name></author><category term="SOTA"/><category term="foundationmodel"/><summary type="html"><![CDATA[DeepMind releases AlphaGenome, a unifying DNA sequence model that advances regulatory variant-effect prediction, promising to shed fresh light on how the genome orchestrates life.]]></summary></entry><entry><title type="html">Introducing TxGemma: Open models to improve therapeutics development - Google Developers Blog</title><link href="https://eugenebang.github.io/blog/2025/introducing-txgemma-open-models-to-improve-therapeutics-development-google-developers-blog/" rel="alternate" type="text/html" title="Introducing TxGemma: Open models to improve therapeutics development - Google Developers Blog"/><published>2025-03-25T00:00:00+00:00</published><updated>2025-03-25T00:00:00+00:00</updated><id>https://eugenebang.github.io/blog/2025/introducing-txgemma-open-models-to-improve-therapeutics-development--------------------------------------google-developers-blog</id><content type="html" xml:base="https://eugenebang.github.io/blog/2025/introducing-txgemma-open-models-to-improve-therapeutics-development-google-developers-blog/"><![CDATA[<p>Developing a new therapeutic is risky, notoriously slow, and can cost billions of dollars. 90% of drug candidates fail beyond phase 1 trials. Today, weâ€™re excited to release TxGemma, a collection of open models designed to improve the efficiency of therapeutic development by leveraging the power of large language models.Building on Google DeepMindâ€™s Gemma, a family of lightweight, state-of-the-art open models, TxGemma is specifically trained to understand and predict the properties of therapeutic entities throughout the entire discovery process, from identifying promising targets to helping predict clinical trial outcomes. This can potentially shorten the time from lab to bedside, and reduce the costs associated with traditional methods.Last October, we introduced Tx-LLM, a language model trained for a variety of therapeutic tasks related to drug development. After huge interest to use and fine-tune this model for therapeutic applications, we have developed its open successor at a practical scale: TxGemma, which we are releasing today for developers to adapt to their own therapeutic data and tasks.TxGemma models, fine-tuned from Gemma 2 using 7 million training examples, are open models designed for prediction and conversational therapeutic data analysis. These models are available in three sizes: 2B, 9B and 27B. Each size includes a â€˜predictâ€™ version, specifically tailored for narrow tasks drawn from Therapeutic Data Commons, for example predicting if a molecule is toxic.These tasks encompass:The largest TxGemma model (27B predict version) delivers strong performance. Itâ€™s not only better than, or roughly equal to, our previous state-of-the-art generalist model (Tx-LLM) on almost every task, but it also rivals or beats many models that are specifically designed for single tasks. Specifically, it outperforms or has comparable performance to our previous model on 64 of 66 tasks (beating it on 45), and does the same against specialized models on 50 of the tasks (beating them on 26). See the TxGemma paper for detailed results.TxGemma also includes 9B and 27B â€˜chatâ€™ versions. These models have general instruction tuning data added to their training, enabling them to explain their reasoning, answer complex questions, and engage in multi-turn discussions. For example, a researcher could ask TxGemma-Chat why it predicted a particular molecule to be toxic and receive an explanation based on the moleculeâ€™s structure. This conversational capability comes at a small cost to the raw performance on therapeutic tasks compared to TxGemma-Predict.As part of the release, weâ€™re including a fine-tuning example Colab notebook that demonstrates how developers can adapt TxGemma to their own therapeutic data and tasks. This notebook uses the TrialBench dataset to show how to fine-tune TxGemma for predicting adverse events in clinical trials. Fine-tuning allows researchers to leverage their proprietary data to create models tailored to their unique research needs, possibly leading to even more accurate predictions that help researchers assess how safe or or effective a potential new therapy might be.Beyond single-step predictions, weâ€™re demonstrating how TxGemma can be integrated into agentic systems to tackle more complex research problems. Standard language models often struggle with tasks requiring up-to-date external knowledge or multi-step reasoning. To address this, weâ€™ve developed Agentic-Tx, a therapeutics-focused agentic system powered by Gemini 2.0 Pro. Agentic-Tx is equipped with 18 tools, including:Agentic-Tx achieves state-of-the-art results on reasoning-intensive chemistry and biology tasks from benchmarks including Humanityâ€™s Last Exam and ChemBench. We are including a Colab notebook with our release to demonstrate how Agentic-Tx can be used to orchestrate complex workflows and answer multi-step research questions.Sorry, your browser doesnâ€™t support playback for this videoYou can access TxGemma on both Vertex AI Model Garden and Hugging Face today. We encourage you to explore the models, try out the inference, fine-tuning, and agent Colab notebooks, and share your feedback! As an open model, TxGemma is designed to be further improved â€“ researchers can fine-tune it with their data for specific therapeutic development use-cases. Weâ€™re excited to see how the community will use TxGemma to accelerate therapeutic discovery.Key contributors to this project include: Eric Wang, Samuel Schmidgall, Fan Zhang, Paul F. Jaeger, Rory Pilgrim and Tiffany Chen. We also thank Shravya Shetty, Dale Webster, Avinatan Hassidim, Yossi Matias, Yun Liu, Rachelle Sico, Phoebe Kirk, Fereshteh Mahvar, Can â€œJohnâ€ Kirmizi, Fayaz Jamil, Tim Thelin, Glenn Cameron, Victor Cotruta, David Fleet, Jon Shlens, Omar Sanseviero, Joe Fernandez, and JoÃ«lle Barral, for their feedback and support throughout this project.Simulating a neural operating system with Gemini 2.5 Flash-LiteIntroducing Gemma 3n: The developer guideUnlock deeper insights with the new Python client library for Data Commons</p>]]></content><author><name></name></author><summary type="html"><![CDATA[TxGemma is a collection of open models designed to improve efficiency of therapeutic development using language models.]]></summary></entry></feed>